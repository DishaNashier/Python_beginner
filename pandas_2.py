# -*- coding: utf-8 -*-
"""pandas_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mZCJOCYwjarY29aZHcoA_ZcGHJ7s3GMT
"""

!wget "https://drive.google.com/uc?export=download&id=1E3bwvYGf1ig32RmcYiWc0IXPN-mD_bI_" -O mckinsey.csv
import pandas as pd
# df=pd.read_csv('/content/sample_data/mckinsey.csv')

# Topics to be covered
#************************************************************************************************************
# Slicing both on rows and columns
# Sorting data frames
# Concatination and merging data frames
#*************************************************************************************************************
# While adding permanent changes to data frame either update the assigned variable (df) or add inplace=True
# Add a new row - df.append(row_key_value_pair, ignore_index=True)
#                 df.loc[index]=["List of row elements"]
#                 df.loc[len(df.index)] = ['List of row elements'] #length of data frame is equal to (last_index+1) poistion
# Duplicates in dataframe -
#                           df.duplicated() -- will give boolean outputs
#                           [df.duplicated()]--will give list
#                           df.loc[df.duplicated()] -- will give table of duplicates
#                           df.drop_duplicates() --will drop duplicate rows
# Reset indexes is required if any row is dropped-
#                                                 df.reset_index(drop=True,inplace=True)
# Rows and Columns - SLICING
#                    df.iloc[1:4] # will follow implicit indexing, will slice rows
#                    df.iloc[1:4:2] # will follow implicit indexing, will slice rows, skipping 2 rows
#                    df.loc[1:3,2:3] # df.loc[rows_range:columns_range]
#                    df.loc[1:4,["year","life_exp"]] #df.loc[rows_range:columns_names1, columns_names2]
#                    df.iloc[1:10:2][['year','country']], df.iloc[rows_slicing][[column1,column2]]
#                    df[["column_name"]] -- Table
#                    le=df["column_name"]--list of column items
#                    le.mean()
#
# Rows and Columns - SORTING
#                    df.sort_values(by ="column_name",ascending=False) #by default in ascending order
#                    df.sort_values(by=["column1","column2"], ascending=[True,False]) #sorting will be on basis of column1, second priority is given to column2
#
# Rows and Columns - CONCATINATION
#ðŸ’¡Note- For concatination Number or rows and Number of columns should be same in both data frames
#
#                    pd.concat([df1,df2],ignore_index=True) #by default axis=0/ Row wise concatination
#                    pd.concat([df1,df2],axis=1) # column wise concatination
#
# Rows and Columns - MERGE
# merge- merges data based on common columns
# merge is like joins in sql
#                    df1.merge(df2) #inner join # only data common between both tables
#                    df1.merge(df2,how="inner") # by default how="inner"
#                    df1.merge(df2,how="left")
#                    df1.merge(df2,how="right")
#                    df1.merge(df2,how="outer")
#                    df1.merge(df2,how="outer",on="common_column")
# if columns name is different but same data we have two option either rename column name or specify both column names using "ON"
#                    df.rename({'column_name':'new_coulmn_name'},inplace=True,axis=1)
#                    df1.merge(df2,how="outer",left_on="column_names_df1",right_on="column_name_df2")

#explicit indexing- last index is included
df.loc[0:3]

# implicit indexing- last index is not included
df.iloc[0:3]

# Add a new row
row={"country":"India","year":"2024","population":1436697241, "life_exp":37.08, "gdp_cap":900.5}
df=df.append(row,ignore_index=True)

df.loc[1705]=["India",	2024, 1436697241,	"Asia",37.080,900.500000]

df.tail()

df=df.drop(index=1704,axis=0) #inplace=True

df

df.drop(3,inplace=True,axis=0)

df

df.loc[3] #explicit index 3 got droped

df.iloc[3]

len(df.index)

d=[len(df.index)]

d

df.reset_index(drop=True,inplace=True)

df.loc[len(df.index)] = ['India',2000,13500000,'Asia',37.08,900.23]
df.loc[len(df.index)] = ['Sri Lanka',2022 ,130000000,'Asia',80.00,500.00]
df.loc[len(df.index)] = ['Sri Lanka',2022 ,130000000,'Asia',80.00,500.00]
df.loc[len(df.index)] = ['India',2000 ,13500000,'Asia',80.00,900.23]

df

df.duplicated()

df.loc[df.duplicated()]

df=df.drop_duplicates()
df.reset_index(drop=True,inplace=True)

df

"""## Rows and Columns"""

df.head()

df.iloc[1:4]

df.iloc[1:4,1:3] #[rows,columns]

df.loc[1:3,2:3]# we do not have any column containing 1-n numbers according to row so this will throw an error

df.loc[1:4,"year":"population"]

df.loc[1:4,"year":"life_exp"]

df.loc[1:4,["year","life_exp"]]

df

df.iloc[1:10:2]

df.iloc[1:10:2][['year','country']]

df[["life_exp"]]

le=df["life_exp"]

le.mean()

df.sort_values(by ="life_exp",ascending=False)

df.sort_values(by=["year","life_exp"], ascending=[True,False]) #sorting will be on basis year first, second priority is given to life_exp

# How to sort a pandas data frame in place based on the values of Columns country and population in desc order?
df.sort_values(by=["country","population"],ascending=False)

"""# Concatinating dataframes"""

# For concatination Number or rows and Number of columns should be same in both data frames

users = pd.DataFrame({"userid":[1, 2, 3], "name":["sharadh", "shahid", "khusalli"]})
users

msgs = pd.DataFrame({"userid":[1, 1, 2, 4], "msg":['hmm', "acha", "theek hai", "nice"]})
msgs

pd.concat([users,msgs],ignore_index=True) #by default axis=0/ Row wise concatination

pd.concat([users,msgs],axis=1) # column wise concatination

# NaN is not an integer,nor a number, its something like infinity, NaN is float type
# Therefore all other values in the userid column got converted into float type

users

msgs

# contination simply attach different data frames, irrespective of if something is common or not
# merge- merges data based on common columns
# merge is like joins in sql

users.merge(msgs) #inner join # only data common between both tables

users.merge(msgs,how="inner") # by default how="inner"

# check users data and their msgs if avaialable
users.merge(msgs,how="left")

# all msgs and their user if available
users.merge(msgs,how="right")

users.merge(msgs,how="outer")

users.merge(msgs,how="outer",on="userid")

users.rename({'userid':'id'},inplace=True,axis=1)
users

users.merge(msgs,how="outer",on="userid")

users.merge(msgs,how="outer",left_on="id",right_on="userid")

import pandas as pd
df1 = pd.DataFrame({'A':[10,30], 'B':[20,40], 'C':[30, 60]})
df2 = pd.DataFrame({'A':[10,30], 'C':[30, 60]})

df1

df2

df2.merge(df1, on = 'A', how = 'outer')

#IMDB dataset
!gdown 1s2TkjSpzNc4SyxqRrQleZyDIHlc7bxnd
!gdown 1Ws-_s1fHZ9nHfGLVUQurbHDvStePlEJm

movies=pd.read_csv('movies.csv',index_col=0)
directors=pd.read_csv('directors.csv',index_col=0)

movies.head()

directors.head()

data = movies.merge(directors, left_on = 'director_id', right_on = 'id', how = 'left')

data.shape

data.head()

